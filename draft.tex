\documentclass[11pt]{article}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[linesnumbered, vlined, ruled]{algorithm2e}
%\usepackage[linesnumbered, ruled]{algorithm2e}
\usepackage{ascmac}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsfonts}
%\usepackage{bm}
\usepackage{graphicx}
%\usepackage{booktabs}
%\usepackage{multirow}
%\usepackage{subfig}
%\usepackage{color}
%\usepackage{tabularx}
%\usepackage{lscape}
\usepackage{fullpage}
%\usepackage{floatrow}
%sidecap
\usepackage{url}
\usepackage{floatrow}
%\usepackage[top=1truemm,bottom=10truemm,left=10truemm,right=10truemm]{geometry}
%\usepackage[top=10truemm]{geometry}
\usepackage{listings}

%\usepackage[whole]{bxcjkjatype}

\def\vector#1{\mbox{\boldmath $#1$}}
\newcommand{\CR}{C}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% \setlength{\textwidth}{\fullwidth}
%% \setlength{\textheight}{40\baselineskip}
%% \addtolength{\textheight}{\topskip}
%% \setlength{\voffset}{-0.2in}
%% \setlength{\topmargin}{0pt}
%% \setlength{\headheight}{0pt}
%% \setlength{\headsep}{0pt}


\renewcommand{\arraystretch}{1.2}
%\renewcommand{\tablename}{Table }
%\renewcommand{\refname}{References}

\def\vector#1{\mbox{\boldmath $#1$}}


 \renewcommand{\thetable}{\arabic{table}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
\title{Genetic Algorithm Exercise\\ {\normalsize Genetic Algorithms for Single-objective Binary, Permutation, and Continuous Optimization}}
\date{August 20th, 2017}
%\date{}
%\author{Ryoji Tanabe}
%% \date{\vspace{-2.5zw}}
\maketitle


%\vspace{12zw}


\section{Introduction}

Single-objective optimization is the problem of finding a solution $\vector{x}$ that minimizes or maximizes an objective function $f$.
Optimization problems can be roughly classified into combinatorial (discrete) optimization problems and continuous optimization problems.
The class of combinatorial optimization problems can be further classified into binary and permutation optimization problems.
This report presents seven programming exercises of genetic algorithms for single-objective binary, permutation, and continuous optimization.
They are described in Section 2, 3 and 4, respectively.

You can learn how to implement genetic algorithms and the basic programming skills through experience.
The exercises presented in this report do not require any expert programming skills.
Also, you can implement genetic algorithms by any programming language (e.g., C, C++, Java, Matlab/Octave, Python, ...).


\section{GA for Single objective binary optimization problems}

\subsection{One-max problem}


The one-max problem is the most simple optimization problem.
The solution of the one-max problem is a $D$-dimensional binary vector $\vector{x} = (x_1, ..., x_D)^{\rm T} \in \{0, 1\}^D$.
The objective function $f: \mathbb{Z}^D \rightarrow \mathbb{Z}$ to be maximized is defined as follows:
%
\begin{align}
\label{eqn:onemax}
f(\vector{x}) = \sum^D_{i=1} x_i
\end{align}
%
The number of variables whose values are 1 is the objective function value $f(\vector{x})$ of the solution $\vector{x}$.
For example, if $\vector{x} = (1, 0, 1, 1, 0)^{\rm T}$, $f(\vector{x}) = 3$.
As seen from equation \eqref{eqn:onemax}, the optimal solution $\vector{x}^*$ is clearly $\vector{x}^* = (1, ..., 1)^{\rm T}$.

\subsection{Exercise 1: Implement $(\mu + 1)$-GA}

The goal of this exercise is to implement $(\mu + 1)$-GA.
Traditionally, $(\mu + \lambda)$ notation is used in the evolutionary computation community, where $\mu$ and $\lambda$ represent the population size and the number of children respectively.
For example, $(123 + 456)$-GA indicates that the the population size and the number of children are 123 and 456 respectively.
The $(\mu + 1)$-GA, also known as steady-state GA, is a special case of $(\mu + \lambda)$-GA when $\lambda = 1$.
Since $(\mu + 1)$-GA is easy to implement than $(\mu + \lambda)$-GA, it is suitable as the first exercise.

All variables used in this section are as follows:
%
\begin{itemize}
\item $t$: The number of generation (or iterations)
\item $n$: The number of function evaluations. In general, $n \neq t$. However, $n = t$ only in the case of $(\mu + 1)$-GA
\item $n^{{\rm max}}$: The maximum number of function evaluations
\item $\mu$: The population size
\item $\lambda$: The number of children
\item $\vector{P}$: The population. $\vector{P} = \{\vector{x}^1, ..., \vector{x}^{\mu} \}$
\item $\vector{x}^{i} = (x^{i} _1, ..., x^{i}_D)^{\rm T}$: The $i$-th individual in the population $\vector{P}$
\item $\vector{u} = (u_1, ..., u_D)^{\rm T}$: A child individual
\item  $\vector{x}^{\rm bsf}$: The best-so-far solution found during the search process
\item $p_m \in [0,1]$: Mutation rate. The most widely used setting is $p_m = 1/D$
\end{itemize}

Algorithm \ref{alg:ssga} shows the overall procedure of $(\mu + 1)$-GA.
Algorithm \ref{alg:initialization_binary}, \ref{alg:ux} and \ref{alg:bitflipmut} also describe the procedure of the population initialization, uniform crossover, and bit-flip mutation, respectively.
The search should be terminated when $n$ reaches $n^{{\rm max}}$ or the optimal solution is found (in case of $f(\vector{x}^{\rm bsf}) = f(\vector{x}^*)$).
If the $(\mu + 1)$-GA which you implemented can successfully find the optimal solution on the one-max problem instance with $D=50$, this exercise is finished.

%After that, $(\mu + 1)$-GA (version 2) described in Algorithm \ref{alg:ssga-v2} should be implemented.
%% The generation alternation model of the version 1 is so-called the deterministic crowding.
%% The version 2 is a more typical GA model.
%% Since it is more easy to implement the version 1 than the version 2, the two-stage exercise was set.
%% Also, you can understand the enviromental selection models of Differential Evolution (DE) and Particle Swarm Optimization (PSO) by implementating the version 1.

\clearpage

\IncMargin{0.5em}
\begin{algorithm}[t]
%\scriptsize
%\footnotesize
\small
%\SetAlgoLined
\SetSideCommentRight
%\KwData{this text}
%\KwResult{how to write algorithm with \LaTeX2e }
\tcp{\  Initialization phase}
$t \leftarrow 1$\;
Initialize the population $\vector{P} =\{ \vector{x}^{1}, ..., \vector{x}^{\mu}\}$ randomly (Algorithm \ref{alg:initialization_binary})\;
Evaluate each individual $\vector{x}^{i}$ ($i \in \{1, ..., \mu\}$) in $\vector{P}$ by equation \eqref{eqn:onemax}\;
\While{The termination criteria are not met}{
  \tcp{\  Step 1. Mating selection}
  Randomly select two parent individuals $\vector{x}^{a}$ and $\vector{x}^{b}$ from $\vector{P}$ so that $a \neq b$\;
  \tcp{\  Step 2. Variation operator1: Crossover}
  Generate a child $\vector{u}$ by applying uniform crossover  (Algorithm \ref{alg:ux}) to  $\vector{x}^{a}$ and $\vector{x}^{b}$\;
  \tcp{\  Step 3. Variation operator2: Mutation}
  Apply bit-flip mutation (Algorithm \ref{alg:bitflipmut}) with the mutation probability $p_m = 1/D$ to $\vector{u}$\;
  \tcp{\  Step 4. Evaluate the child $\vector{u}$}
  Evaluate the child $\vector{u}$ by equation \eqref{eqn:onemax}\;
  $n \leftarrow n + 1$\;
  \tcp{\  Step 5. Update the best-so-far solution $\vector{x}^{\rm bsf}$}
  \If{$f(\vector{u}) > f(\vector{x}^{\rm bsf})$} {
    $\vector{x}^{\rm bsf} \leftarrow \vector{u}$\;
  }
  \tcp{\  Step 6. Environmental selection}
  Randomly select an individual $\vector{x}^{c}$ from $\vector{P}$\;
  \If{$f(\vector{u}) \geq f(\vector{x}^{c})$} {
    $\vector{x}^{c} \leftarrow \vector{u}$\;
  }
  $t \leftarrow t + 1$\;
}
Show the best-so-far solution $\vector{x}^{\rm bsf}$ and its objective function value $f(\vector{x}^{\rm bsf})$ to an user (you)\;
\caption{$(\mu + 1)$-GA}
\label{alg:ssga}
\end{algorithm}\DecMargin{0.5em}




\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
  \tcp{\  For each individual $\vector{x}^i$ in the population $\vector{P} = \{\vector{x}^1, ..., \vector{x}^{\mu} \}$}
\For{$i \in \{1, ..., \mu\}$}{
  \tcp{\  For each decision variable $x_j$ in the solution $\vector{x} = (x_1, ..., x_{D})^{\rm T}$}
    \For{$j \in \{1, ..., D\}$}{
    \uIf{${\rm rand}[0,1] < 0.5$}{
        $x^{i}_{j} = 0$\;
      }
      \Else{
        $x^{i}_{j} = 1$\;
      }
    }
  }
\caption{The initialization procedure of the population}
\label{alg:initialization_binary}
\end{algorithm}\DecMargin{0.5em}



\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
\For{$j \in \{1, ..., D\}$}{
  \uIf{${\rm rand}[0,1] < 0.5$}{
      $u^{i}_{j} = x^{a}_{j}$\;
    }
    \Else{
      $u^{i}_{j} = x^{b}_{j}$\;
    }
  }
\caption{Uniform crossover}
\label{alg:ux}
\end{algorithm}\DecMargin{0.5em}



\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
\For{$j \in \{1, ..., D\}$}{
  \If{${\rm rand}[0,1] < p_m$}{
  \uIf{$u_j = 0$}{
    $u_j = 1$\;
    }
    \Else{
    $u_j = 0$\;
    }
  }
}
\caption{Bit-flip mutation}
\label{alg:bitflipmut}
\end{algorithm}\DecMargin{0.5em}


\clearpage

\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
Randomly select four individuals $\vector{x}^{d}, \vector{x}^{e}, \vector{x}^{f}$ and $\vector{x}^{g}$ from the population $\vector{P}$ so that $d \neq e \neq f \neq g$\;
\tcp{\  Select a parent individual $\vector{x}^{a}$}
\uIf{$f(\vector{x}^{d}) > f(\vector{x}^{e})$}{
  $\vector{x}^{a} \leftarrow \vector{x}^{d}$\;
}
\Else{
  $\vector{x}^{a} \leftarrow \vector{x}^{e}$\;
}
\tcp{\  Select another parent individual $\vector{x}^{b}$}
\uIf{$f(\vector{x}^{f}) > f(\vector{x}^{g})$}{
  $\vector{x}^{b} \leftarrow \vector{x}^{f}$\;
}
\Else{
  $\vector{x}^{b} \leftarrow \vector{x}^{g}$\;
}
\caption{Binary tournament selection without replacement for the selection of parent individuals $\vector{x}^{a}$ and $\vector{x}^{b}$}
\label{alg:tswor}
\end{algorithm}\DecMargin{0.5em}


%\clearpage

\subsection{Exercise 2: Change the environmental selection method in Algorithm \ref{alg:ssga}}

In Algorithm \ref{alg:ssga}, an individual $\vector{x}^c$, which is possibly replaced by a child $\vector{u}$, is uniformly randomly selected (line 12).
What happens when the environmental selection method is changed as follows?
%
\begin{itemize}
\item Select the worst individual $\vector{x}^{\rm worst}$ in $\vector{P}$ and $\vector{x}^{c} = \vector{x}^{\rm worst}$
\end{itemize}

\subsection{Exercise 3: Change the mating selection method in Algorithm \ref{alg:ssga}}

In Algorithm \ref{alg:ssga}, parent individuals $\vector{x}^a$ and $\vector{x}^b$ are randomly selected from $\vector{P}$ (line 5).
What happens when the mating selection method is modified to binary tournament selection described in Algorithm \ref{alg:tswor}?


%\begin{align}
\subsection{Exercise 4: Evaluate the performance of the GA on the order-3 deceptive problem}

In principle, the GA which you implemented for the one-max problem can be applied any binary optimization problems by changing the objective function (i.e., equation \eqref{eqn:onemax}).
The goal of this exercise is to evaluate  the performance of the GA on the order-3 deceptive problem.
While the landscape of the onemeax problem is unimodal, that of the order-3 deceptive problem is multimodal.
A three-dimensional order-3 deceptive problem (i.e., $\vector{x} = (x_1, x_2, x_3)^{\rm T}$) is defined as follows \cite{LiOH11}:
%
\begin{align}
\label{eqn:3order}
&f(1, 1, 1) = 30,\\\notag
&f(1, 1, 0) = 0, f(1, 0, 1) = 0, f(0, 1, 1) = 0,\\\notag
&f(1, 0, 0) = 14,  f(0, 1, 0) = 22, f(0, 0, 1) = 26,\\\notag
&f(0, 0, 0) = 28
\end{align}
%
The optimal and sub-optimal solutions of this problem are $\vector{x}^{*} = (1, 1, 1)^{\rm T}$ and $\vector{x}^{{\rm sub}*} = (0, 0, 0)^{\rm T}$, respectively.

A $D$-dimensional order-3 deceptive problem (i.e., $\vector{x} = (x_1, ..., x_D)^{\rm T}$) consists of $D$ three-dimensional problems defined in \eqref{eqn:3order}, where $D$ must be set as a multiple of three (e.g., $D=12, 27, 90$).
Algorithm \ref{alg:three-order-deceptive-problem} shows the calculation method of the objective function value of the $D$-dimensional order-3 deceptive problem.
Clearly, the optimal solution of this problem is $\vector{x}^* = (1, ..., 1)^{\rm T}$.


\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
$s \leftarrow 0$\;
$j \leftarrow 1$\;
\While{$j < D$}{
  $\vector{x}^{\rm tmp} \leftarrow (x_{j}, x_{j+1}, x_{j+2})$\;  
  $s \leftarrow s + f(\vector{x}^{\rm tmp})$ (see equation \eqref{eqn:3order})\;
  $j \leftarrow j + 3$\;
}
$f(\vector{x}) \leftarrow s$\;
\caption{The procedure of calculating the objective function value $f(\vector{x})$ of the order-3 deceptive problem}
\label{alg:three-order-deceptive-problem}
\end{algorithm}\DecMargin{0.5em}




\subsubsection{Exercise 5: Implement $(\mu+\lambda)$-GA}

The goal of this exercise is to implement $(\mu + \lambda)$-GA, which is a generalized version of $(\mu+1)$-GA.
While only one child is generated per one iteration in $(\mu+1)$-GA, $\lambda$ children are generated simultaneously in $(\mu+\lambda)$-GA.
Although there have been a number of variants of $(\mu+\lambda)$-GA,  a $(\mu+\lambda)$-GA with truncation selection like CHC \cite{Eshelman90} is considered in this exercise.
Algorithm \ref{alg:mulambdaga} shows the details of $(\mu+\lambda)$-GA to be implemented.



\IncMargin{0.5em}
\begin{algorithm}[t]
%\scriptsize
%\footnotesize
%\small
%\SetAlgoLined
\SetSideCommentRight
%\KwData{this text}
%\KwResult{how to write algorithm with \LaTeX2e }
\tcp{\  Initialization phase}
$t \leftarrow 1$\;
Initialize the population $\vector{P} =\{ \vector{x}^{1}, ..., \vector{x}^{\mu}\}$ randomly (Algorithm \ref{alg:initialization_binary})\;
Evaluate each individual $\vector{x}^{i}$ ($i \in \{1, ..., \mu\}$) in $\vector{P}$ by equation \eqref{eqn:onemax}\;
\While{The termination criteria are not met}{
  Children $\vector{Q} \leftarrow \emptyset$\;
  \For{$i \in \{1, ..., \lambda\}$}{  
    \tcp{\  Step 1. Mating selection}
    Randomly select two parent individuals $\vector{x}^{a}$ and $\vector{x}^{b}$ from $\vector{P}$ so that $a \neq b$\;
    \tcp{\  Step 2. Crossover operator}
    Generate a child $\vector{u}$ by applying uniform crossover  (Algorithm \ref{alg:ux}) to  $\vector{x}^{a}$ and $\vector{x}^{b}$\;
    \tcp{\  Step 3. Mutation operator}
    Apply bit-flip mutation (Algorithm \ref{alg:bitflipmut}) with the mutation probability $p_m = 1/D$ to $\vector{u}$\;
    \tcp{\  Step 4. Evaluate the child $\vector{u}$}
    Evaluate the child $\vector{u}$ by equation \eqref{eqn:onemax}\;
    $n \leftarrow n + 1$\;
    $\vector{Q} \leftarrow \vector{Q} \cup \{\vector{u}\}$\;
    \tcp{\  Step 5. Update the best-so-far solution $\vector{x}^{\rm bsf}$}
    \If{$f(\vector{u}) > f(\vector{x}^{\rm bsf})$} {
      $\vector{x}^{\rm bsf} \leftarrow \vector{u}$\;
    }
  }
  \tcp{\  Step 6. Environmental selection ($\vector{R}$ is a union of the population and children)}
  $\vector{R} \leftarrow \vector{P} \cup \vector{Q}$, where $\vector{R} = \{\vector{x}^1, ..., \vector{x}^{\mu}, \vector{u}^{1}, ..., \vector{u}^{\lambda}\}$\;
  Sort individuals in $\vector{R}$ according to their objective function values\;
  $\vector{P} \leftarrow $ the first half of individuals in $\vector{R}$\;
  $t \leftarrow t + 1$\;
}
Show the best-so-far solution $\vector{x}^{\rm bsf}$ and its objective function value $f(\vector{x}^{\rm bsf})$ to an user (you)\;
\caption{$(\mu+\lambda)$-GA}
\label{alg:mulambdaga}
\end{algorithm}\DecMargin{0.5em}



\clearpage






\section{GA for permutation optimization problems}

In permutation optimization problems, the solution is defined as a permutation such as $\vector{x} = (3, 1, 4, 2)^{\rm T}$.
Here, the TSP, which is the most popular permutation optimization problem, is considered.

In addition to the TSP, there are a number of problems such as Flow Shop Scheduling Problems (FSSPs), Quadratic Assignment Problems (QAPs), and Vehicle Routing Problems (VRPs).
QAPs are easy to understand, and a GA for them is also easy to implement.
If you are interested in the GA for QAPs, you can try it after finishing all exercises.

%If you are insterested in them, you can chalenge them!

\subsection{Traveling Sales-person Problems (TSPs)}

The Traveling Sales-person Problem (TSP) is the problem of finding the shortest tour that visits all cities.
The TSP is not described anymore here because it is very famous. You can find good examples of TSPs anywhere on the internet.


\subsection{Exercise 6: Implement GA for solving TSPs}

The goal of this section is to implement a GA for TSPs.
Both $(\mu + 1)$-GA and $(\mu + \lambda)$-GA are fine.
%
The algorithm \ref{alg:calculation_tour_length}, \ref{alg:ox}, and \ref{alg:mut_inversion} show the calculation method of the tour length, the procedure of Order Crossover (OX) and inversion mutation, respectively.
Although there have been a number of crossover methods for permutation problems, OX is easy to understand and works well on small-scale TSPs.
Figure 2 in \cite{StarkweatherMMWW91} shows a good example of the procedure of OX.
You should use Fisher-Yates's shuffle method\footnote{\url{https://en.wikipedia.org/wiki/Fisher-Yates_shuffle}} or its variants for randomly generating the initial solution $\vector{x}$.

Which TSP instances should be used?
%
TSP instances provided by TSPLIB\footnote{\url{http://www.iwr.uni-heidelberg.de/groups/comopt/software/TSPLIB95/}} are the most commonly used benchmark problems.
However, data of TSP instances cannot currently be downloaded from the TSPLIB website  (Aug 20th, 2017).
Therefore, instead of TSPLIB, you can use data of national TSPs\footnote{\url{http://www.math.uwaterloo.ca/tsp/world/countries.html}}.
Here, the following two TSP instances should be considered as benchmark problems:  the Western Sahara's 29 cities problem (wi29) and the Djibouti's  38 cities problem (dj38).
Their data can be downloaded from \url{http://www.math.uwaterloo.ca/tsp/world/wi29.tsp} and \url{http://www.math.uwaterloo.ca/tsp/world/dj38.tsp}, respectively.
Note that it is impossible for a GA without well-designed strategies to solve large-scale TSPs (e.g., the China's 71,009 cities problem).

There are two ways to store TSP data to your program.
The first way is to save TSP instance data into a file and read it from the program.
The second way is to directly save TSP instance data to you program as follows:


\begin{lstlisting}[basicstyle=\ttfamily\footnotesize, frame=single]
If (target_TSP_instance == ``wi29'') {
  tsp_data_x = {20833.3333, 20900, ..., 27462.5};
  tsp_data_y = {17100, 17066.6667, ..., 12992.2222};
}
Else if (target_TSP_instance == ``dj38'') {
  tsp_data_x = {11003.6111, 11108.6111, ..., 12645};
  tsp_data_y = {42102.5, 42373.8889, ..., 42973.3333};
}
 \end{lstlisting}


\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
$L \leftarrow 0$\;
\For{$j = 1$ \KwTo $D - 1$}{
  $L \leftarrow L + d_{x_j, x_{j+1}}$\;
}
$L \leftarrow L + d_{x_D, x_1}$\;
\caption{The calculation method of the tour length (the objective function value $f(\vector{x})$) of the solution $\vector{x}$. The $D$ is the number of given cities. The $\vector{d}$ is a $D \times D$ matrix whose each element represents the Euclidean distance between two cities. For example, $d_{3, 8}$ is the distance between cities 3 and 8.}
\label{alg:calculation_tour_length}
\end{algorithm}\DecMargin{0.5em}


\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
Randomly select two crossover points $c_1$ and $c_2$ from $\{1, ..., D\}$ so that $c_1 < c_2$\;
$\vector{u} \leftarrow \vector{x}^a$\;
\For{$j = c_1$ \KwTo $c_2$}{
  $h \leftarrow 1$\;
  \While{$x^{b}_j \neq u_h$}{  
    $h \leftarrow h + 1$\;
  }
  $l \leftarrow h + 1$\;
  \While{$l \neq c_2$}{  
    \If{$h = D$}{  
      $h\leftarrow 1$\;
    }
    \If{$l = D$}{  
      $l \leftarrow 1$\;
    }
    $u_h \leftarrow u_l$\;
    $h \leftarrow h + 1$\;
    $l \leftarrow l + 1$\;
  }
}
\For{$j = c_1$ \KwTo $c_2$}{
  $u_j \leftarrow x^b_j$\;
}
\caption{The procedure of order crossover (OX).}
\label{alg:ox}
\end{algorithm}\DecMargin{0.5em}


\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
Randomly select two mutation points $m_1$ and $m_2$ from $\{1, ..., D\}$ so that $m_1 < m_2$\;
$h \leftarrow (m_2 - m_1) / 2$\;
$m_1 \leftarrow m_1 + 1$\;

\For{$k = 1$ \KwTo $h$}{
  $l \leftarrow u_{m_1 + k}$\;
  $u_{m_1 + k}  \leftarrow u_{m_2 - k}$\;
  $u_{m_2 - k}  \leftarrow l$\;
}
\caption{The procedure of inversion mutation.}
\label{alg:mut_inversion}
\end{algorithm}\DecMargin{0.5em}



\clearpage

\section{GA for Continuous Optimization}


\subsection{Continuous Optimization}

Continuous optimization, which frequently appears in the field of engineering optimization, is the problem of finding a $D$-dimensional solution $\vector{x} = (x_1, ..., x_D)^{\rm T} \in \mathbb{S} \subseteq \mathbb{R}^D$  that minimizes an objective function $f: \mathbb{R}^D \rightarrow \mathbb{R}$. $\mathbb{S} = \Pi^D_{j=1} [x^{\rm min}_j, x^{\rm max}_j]$ is the bound-constrained search space where $x^{\rm min}_j \leq x_j \leq x^{\rm max}_j$ for each index $j \in \{1, ..., D\}$.
While decision variables are discrete in combinatorial optimization (including binary and permutation optimization problems), those are real-coded values in continuous optimization.


\subsection{Exercise 7: Implement a GA for continuous optimization}

The goal of this exercise is to implement a GA for solving continuous optimization problems.
Both $(\mu + 1)$-GA and $(\mu + \lambda)$-GA are fine. 
%
The following three test functions (the Sphere, Rastrigin, and Rosenbrock functions) should be used for the performance evaluation of your GA:
\\
%
\noindent $\bullet$ The Sphere function:
%
\begin{align}
\label{eqn:sphere}
f_{\rm Sphere}(\vector{x}) = \sum^D_{j=1} x^2_j
\end{align}
%

$\circ$ $\vector{S} = [-100, 100]^D$, $\vector{x}^* = (0, ..., 0)^{\rm T}$ and $f(\vector{x}^*) = 0$, Function properties: Unimodal, separable

\noindent $\bullet$ The Rastrigin function:
%
\begin{align}
\label{eqn:rastrigin}
f_{\rm Rastrigin}(\vector{x}) =   \sum^{D}_{j = 1} \bigl(x^2_j  - 10{\rm cos}2 \pi (x_j) +10\bigr)
\end{align}
%

$\circ$ $\vector{S} = [-5.12, 5.12]^D$, $\vector{x}^* = (0, ..., 0)^{\rm T}$ and $f(\vector{x}^*) = 0$, Function properties: Strong multimodal, separable

\noindent $\bullet$ The Rosenbrock function:
%
\begin{align}
\label{eqn:rosenbrock}
f_{\rm Rosenbrock}(\vector{x}) = \sum^{D-1}_{j = 1} \bigl(100(x_{j + 1} - x^2_j)^2 + (x_j - 1)^2\bigr)
\end{align}
%

$\circ$ $\vector{S} = [-30, 30]^D$,  $\vector{x}^* = (1, ..., 1)^{\rm T}$ and $f(\vector{x}^*) = 0$,  Function properties: Weak multimodal, nonseparable






The algorithm \ref{alg:initialization_cop} shows how to randomly generate individuals of the initial population.
Although a number of crossover methods have been proposed for continuous optimization, Blend Crossover $\alpha$ (BLX-$\alpha$) \cite{EshelmanS92}\footnote{While I have seen a large number of articles that cite \cite{EshelmanS92}, I have never seen the original paper. It could not be found anywhere.} is easy to implement and performs well. Note that a mutation operator is not applied to a child in this exercise.

For two parent individuals $\vector{x}^{a}$ and $\vector{x}^{b}$, BLX-$\alpha$ generates each element of a child $u_j$ ($j \in \{1, ..., D\}$) in the $\alpha$ times extended range in $[x_{j}^{a}, x_{j}^{b}]$ as follows:
%
\begin{align}
\label{eqn:blx}
u_{j} &= {\rm rand}[A_j, B_j]\\
A_{j} &= {\rm min}(x_{j}^{a}, x_{j}^{b}) - \alpha \, |x_{j}^{a} - x_{j}^{b}| \\
B_{j} &= {\rm max}(x_{j}^{a}, x_{j}^{b}) + \alpha \, |x_{j}^{a} - x_{j}^{b}|
\end{align}
%
where $\alpha > 0$ is the expansion rate, and its recommended setting is 0.5. The functions ${\rm min(\cdot, \cdot)}$ and ${\rm max(\cdot, \cdot)}$ return the smallest and biggest values of given two values, respectively.
For example, ${\rm min(1.2, 3.4)} = 1.2$ and ${\rm max(1.2, 3.4)} = 3.4$.
Good examples of BLX-$\alpha$ can be found in the internet.

It is possible that a child generated by equation \eqref{eqn:blx} violates the bound constraint $\mathbb{S} = \Pi^D_{j=1} [x^{\rm min}_j, x^{\rm max}_j]$.
In such case, the following repairing method should be applied:
%
\begin{align}
\label{eqn:replacing}
  u_j = \begin{cases}
    x^{\rm min}_j & \:  {\rm if} \: u_j < x^{\rm min}_j \\
    x^{\rm max}_j & \:  {\rm if} \: u_j > x^{\rm max}_j \\
    u_j & \:  {\rm otherwise}
  \end{cases}
\end{align}
%
For example, if $u_5 = 123.45$, it should be 100. 

If the GA which you implemented can successfully find the optimal solution\footnote{If $|f(\vector{x}) - f(\vector{x}^{*})| \leq 10^{-8}$, the solution $\vector{x}$ can be treated as the optimal solution.} of the three test functions with $D = 5$, this exercise is finished.



\IncMargin{0.5em}
\begin{algorithm}[t]
%\footnotesize
%\small
\SetKwInOut{Input}{input}\SetKwInOut{Output}{output}
\SetSideCommentRight
\For{$i \in \{1, ..., \mu\}$}{
    \For{$j \in \{1, ..., D\}$}{
        $x^{i}_{j} = (x^{\rm max} - x^{\rm min})  {\rm rand[0,1]} + x^{\rm min}$\;
    }
  }
\caption{The initialization method of the population $\vector{P} = \{\vector{x}^1, ..., \vector{x}^{\mu}\}$, $\vector{x} = (x_1, ..., x_D)^{\rm T}$, where $x^{\rm max}$ and $x^{\rm min}$ are the maximum and minimum values of the search space.}
\label{alg:initialization_cop}
\end{algorithm}\DecMargin{0.5em}




%{\small
%{\footnotesize
%{\scriptsize
%{\tiny
\bibliographystyle{plain}
\bibliography{reference}
%}



\end{document}
